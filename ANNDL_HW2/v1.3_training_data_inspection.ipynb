{"cells":[{"cell_type":"code","execution_count":1,"id":"apPMPAVRXptB","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1945,"status":"ok","timestamp":1702320172991,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"apPMPAVRXptB","outputId":"2a3efdba-6e44-4ceb-a0e0-d788eb855df9"},"outputs":[],"source":["# import ssl\n","# ssl._create_default_https_context = ssl._create_unverified_context\n","# from google.colab import drive\n","# drive.mount(\"/content/gdrive\")\n","pre_path =  \"\"#'/content/gdrive/My Drive/AN2DL_HW2/'"]},{"cell_type":"code","execution_count":2,"id":"f485847c-eff0-4e8c-941d-e75d9eb68ece","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":13631,"status":"ok","timestamp":1702320186616,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"f485847c-eff0-4e8c-941d-e75d9eb68ece","outputId":"8da7e7c4-3a77-4403-9e0f-b7dc3ed81470"},"outputs":[{"data":{"text/html":["<style>:root { --jp-notebook-max-width: 80% !important; }</style>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2023-12-16 02:03:51.377211: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-16 02:03:51.377270: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-16 02:03:51.422830: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-16 02:03:51.500677: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-16 02:03:55.927900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["from IPython.display import display, HTML\n","display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n","\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import warnings\n","import logging\n","import random\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","import seaborn as sns\n","from sklearn.utils.class_weight import compute_class_weight\n","import cv2\n","from statsmodels.tsa.stattools import acf\n","\n","# Setting seeds for reproducibility\n","seed = 42\n","np.random.seed(seed)\n","random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","\n","# Suppressing unnecessary warnings and logs\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","print(tf.__version__)\n","\n","# Additional imports for the model\n","from tensorflow.keras.models import Sequential, Model, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D, Activation,Input,Add\n"]},{"cell_type":"code","execution_count":3,"id":"334a6501-a4d7-47d6-bd09-e6f28c4eb7d6","metadata":{"executionInfo":{"elapsed":18637,"status":"ok","timestamp":1702320205235,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"334a6501-a4d7-47d6-bd09-e6f28c4eb7d6"},"outputs":[],"source":["X_train = np.load(pre_path + 'windowed_training_data/train_X.npy',allow_pickle='TRUE').item()\n","y_train = np.load(pre_path +'windowed_training_data/train_y.npy',allow_pickle='TRUE').item()\n","\n","X_validation = np.load(pre_path +'windowed_training_data/validation_X.npy',allow_pickle='TRUE').item()\n","y_validation = np.load(pre_path +'windowed_training_data/validation_y.npy',allow_pickle='TRUE').item()\n","\n","#X_test = np.load(pre_path +'windowed_training_data/test_X.npy',allow_pickle='TRUE').item()\n","#y_test = np.load(pre_path +'windowed_training_data/test_y.npy',allow_pickle='TRUE').item()"]},{"cell_type":"code","execution_count":4,"id":"qJ4wGnVkZhLw","metadata":{"executionInfo":{"elapsed":906,"status":"ok","timestamp":1702320206129,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"qJ4wGnVkZhLw"},"outputs":[],"source":["window = 206\n","output_shape = 18\n","training_categories = ['A', 'B', 'C', 'D', 'E', 'F']\n","X_train = np.concatenate([X_train[i] for i in training_categories]).reshape(-1,window,1)\n","y_train = np.concatenate([y_train[i] for i in training_categories])\n","\n","X_validation = np.concatenate([X_validation[i] for i in training_categories]).reshape(-1,window,1)\n","y_validation = np.concatenate([y_validation[i] for i in training_categories])\n","\n","#X_test = np.concatenate([X_test[i] for i in training_categories]).reshape(-1,window,1)\n","#y_test = np.concatenate([y_test[i] for i in training_categories])"]},{"cell_type":"code","execution_count":5,"id":"37abc409","metadata":{},"outputs":[],"source":["nan_indices_X = np.isnan(X_train).any(axis=(1, 2))\n","\n","# Find indices of rows with NaN values in y_train\n","nan_indices_y = np.isnan(y_train).any(axis=1)\n","\n","# Combine the indices to get the common rows with NaN values\n","nan_indices = np.logical_or(nan_indices_X, nan_indices_y)\n","\n","# Drop rows with NaN values from both X_train and y_train\n","X_train = X_train[~nan_indices]\n","y_train = y_train[~nan_indices]\n"]},{"cell_type":"markdown","id":"w1Y-gCCh9NWq","metadata":{"id":"w1Y-gCCh9NWq"},"source":["# resnet + conv + Dense"]},{"cell_type":"code","execution_count":6,"id":"RrzgH6Dc8QPv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4338,"status":"ok","timestamp":1702320210457,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"RrzgH6Dc8QPv","outputId":"3261892c-7b76-4692-f4d3-37c3e61b6cc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 206, 1)]             0         []                            \n","                                                                                                  \n"," conv1d (Conv1D)             (None, 206, 32)              128       ['input_1[0][0]']             \n","                                                                                                  \n"," batch_normalization (Batch  (None, 206, 32)              128       ['conv1d[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu (ReLU)                (None, 206, 32)              0         ['batch_normalization[0][0]'] \n","                                                                                                  \n"," conv1d_1 (Conv1D)           (None, 206, 32)              3104      ['re_lu[0][0]']               \n","                                                                                                  \n"," batch_normalization_1 (Bat  (None, 206, 32)              128       ['conv1d_1[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_1 (ReLU)              (None, 206, 32)              0         ['batch_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv1d_2 (Conv1D)           (None, 206, 32)              3104      ['re_lu_1[0][0]']             \n","                                                                                                  \n"," batch_normalization_2 (Bat  (None, 206, 32)              128       ['conv1d_2[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," add (Add)                   (None, 206, 32)              0         ['re_lu[0][0]',               \n","                                                                     'batch_normalization_2[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," re_lu_2 (ReLU)              (None, 206, 32)              0         ['add[0][0]']                 \n","                                                                                                  \n"," max_pooling1d (MaxPooling1  (None, 103, 32)              0         ['re_lu_2[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," conv1d_3 (Conv1D)           (None, 103, 64)              6208      ['max_pooling1d[0][0]']       \n","                                                                                                  \n"," batch_normalization_3 (Bat  (None, 103, 64)              256       ['conv1d_3[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_3 (ReLU)              (None, 103, 64)              0         ['batch_normalization_3[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv1d_5 (Conv1D)           (None, 103, 64)              2112      ['max_pooling1d[0][0]']       \n","                                                                                                  \n"," conv1d_4 (Conv1D)           (None, 103, 64)              12352     ['re_lu_3[0][0]']             \n","                                                                                                  \n"," batch_normalization_5 (Bat  (None, 103, 64)              256       ['conv1d_5[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," batch_normalization_4 (Bat  (None, 103, 64)              256       ['conv1d_4[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," add_1 (Add)                 (None, 103, 64)              0         ['batch_normalization_5[0][0]'\n","                                                                    , 'batch_normalization_4[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," re_lu_4 (ReLU)              (None, 103, 64)              0         ['add_1[0][0]']               \n","                                                                                                  \n"," max_pooling1d_1 (MaxPoolin  (None, 51, 64)               0         ['re_lu_4[0][0]']             \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_6 (Conv1D)           (None, 51, 64)               12352     ['max_pooling1d_1[0][0]']     \n","                                                                                                  \n"," batch_normalization_6 (Bat  (None, 51, 64)               256       ['conv1d_6[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_5 (ReLU)              (None, 51, 64)               0         ['batch_normalization_6[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv1d_7 (Conv1D)           (None, 51, 64)               12352     ['re_lu_5[0][0]']             \n","                                                                                                  \n"," batch_normalization_7 (Bat  (None, 51, 64)               256       ['conv1d_7[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," add_2 (Add)                 (None, 51, 64)               0         ['max_pooling1d_1[0][0]',     \n","                                                                     'batch_normalization_7[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," re_lu_6 (ReLU)              (None, 51, 64)               0         ['add_2[0][0]']               \n","                                                                                                  \n"," max_pooling1d_2 (MaxPoolin  (None, 25, 64)               0         ['re_lu_6[0][0]']             \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_8 (Conv1D)           (None, 25, 128)              24704     ['max_pooling1d_2[0][0]']     \n","                                                                                                  \n"," batch_normalization_8 (Bat  (None, 25, 128)              512       ['conv1d_8[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," re_lu_7 (ReLU)              (None, 25, 128)              0         ['batch_normalization_8[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv1d_10 (Conv1D)          (None, 25, 128)              8320      ['max_pooling1d_2[0][0]']     \n","                                                                                                  \n"," conv1d_9 (Conv1D)           (None, 25, 128)              49280     ['re_lu_7[0][0]']             \n","                                                                                                  \n"," batch_normalization_10 (Ba  (None, 25, 128)              512       ['conv1d_10[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," batch_normalization_9 (Bat  (None, 25, 128)              512       ['conv1d_9[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," add_3 (Add)                 (None, 25, 128)              0         ['batch_normalization_10[0][0]\n","                                                                    ',                            \n","                                                                     'batch_normalization_9[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," re_lu_8 (ReLU)              (None, 25, 128)              0         ['add_3[0][0]']               \n","                                                                                                  \n"," max_pooling1d_3 (MaxPoolin  (None, 12, 128)              0         ['re_lu_8[0][0]']             \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_11 (Conv1D)          (None, 12, 128)              49280     ['max_pooling1d_3[0][0]']     \n","                                                                                                  \n"," batch_normalization_11 (Ba  (None, 12, 128)              512       ['conv1d_11[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," re_lu_9 (ReLU)              (None, 12, 128)              0         ['batch_normalization_11[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv1d_12 (Conv1D)          (None, 12, 128)              49280     ['re_lu_9[0][0]']             \n","                                                                                                  \n"," batch_normalization_12 (Ba  (None, 12, 128)              512       ['conv1d_12[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," add_4 (Add)                 (None, 12, 128)              0         ['max_pooling1d_3[0][0]',     \n","                                                                     'batch_normalization_12[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," re_lu_10 (ReLU)             (None, 12, 128)              0         ['add_4[0][0]']               \n","                                                                                                  \n"," max_pooling1d_4 (MaxPoolin  (None, 6, 128)               0         ['re_lu_10[0][0]']            \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_13 (Conv1D)          (None, 6, 256)               98560     ['max_pooling1d_4[0][0]']     \n","                                                                                                  \n"," batch_normalization_13 (Ba  (None, 6, 256)               1024      ['conv1d_13[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," re_lu_11 (ReLU)             (None, 6, 256)               0         ['batch_normalization_13[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv1d_15 (Conv1D)          (None, 6, 256)               33024     ['max_pooling1d_4[0][0]']     \n","                                                                                                  \n"," conv1d_14 (Conv1D)          (None, 6, 256)               196864    ['re_lu_11[0][0]']            \n","                                                                                                  \n"," batch_normalization_15 (Ba  (None, 6, 256)               1024      ['conv1d_15[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," batch_normalization_14 (Ba  (None, 6, 256)               1024      ['conv1d_14[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," add_5 (Add)                 (None, 6, 256)               0         ['batch_normalization_15[0][0]\n","                                                                    ',                            \n","                                                                     'batch_normalization_14[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," re_lu_12 (ReLU)             (None, 6, 256)               0         ['add_5[0][0]']               \n","                                                                                                  \n"," max_pooling1d_5 (MaxPoolin  (None, 3, 256)               0         ['re_lu_12[0][0]']            \n"," g1D)                                                                                             \n","                                                                                                  \n"," conv1d_16 (Conv1D)          (None, 3, 256)               196864    ['max_pooling1d_5[0][0]']     \n","                                                                                                  \n"," batch_normalization_16 (Ba  (None, 3, 256)               1024      ['conv1d_16[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," re_lu_13 (ReLU)             (None, 3, 256)               0         ['batch_normalization_16[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv1d_17 (Conv1D)          (None, 3, 256)               196864    ['re_lu_13[0][0]']            \n","                                                                                                  \n"," batch_normalization_17 (Ba  (None, 3, 256)               1024      ['conv1d_17[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," add_6 (Add)                 (None, 3, 256)               0         ['max_pooling1d_5[0][0]',     \n","                                                                     'batch_normalization_17[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," re_lu_14 (ReLU)             (None, 3, 256)               0         ['add_6[0][0]']               \n","                                                                                                  \n"," global_average_pooling1d (  (None, 256)                  0         ['re_lu_14[0][0]']            \n"," GlobalAveragePooling1D)                                                                          \n","                                                                                                  \n"," dense (Dense)               (None, 18)                   4626      ['global_average_pooling1d[0][\n","                                                                    0]']                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 968722 (3.70 MB)\n","Trainable params: 964050 (3.68 MB)\n","Non-trainable params: 4672 (18.25 KB)\n","__________________________________________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","def residual_block(x, filters, kernel_size=3, stride=1):\n","    y = layers.Conv1D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n","    y = layers.BatchNormalization()(y)\n","    y = layers.ReLU()(y)\n","\n","    y = layers.Conv1D(filters, kernel_size=kernel_size, padding='same')(y)\n","    y = layers.BatchNormalization()(y)\n","\n","    # If the number of filters is different or the stride is not 1, add a convolutional layer to the shortcut\n","    if stride != 1 or x.shape[-1] != filters:\n","        x = layers.Conv1D(filters, kernel_size=1, strides=stride, padding='same')(x)\n","        x = layers.BatchNormalization()(x)\n","\n","    out = layers.add([x, y])\n","    out = layers.ReLU()(out)\n","    return out\n","\n","def build_resnet(input_shape, num_classes=1):\n","    input_layer = layers.Input(shape=input_shape)\n","\n","    # Initial convolutional layer\n","    x = layers.Conv1D(32, kernel_size=3, strides=1, padding='same')(input_layer)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","\n","\n","    x = residual_block(x, filters=32, stride=1)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = residual_block(x, filters=64, stride=1)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","\n","    x = residual_block(x, filters=64, stride=1)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = residual_block(x, filters=128, stride=1)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = residual_block(x, filters=128, stride=1)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = residual_block(x, filters=256, stride=1)\n","    x = MaxPooling1D(pool_size=2)(x)\n","\n","    x = residual_block(x, filters=256, stride=1)\n","    x = layers.GlobalAveragePooling1D()(x)\n","\n","    output_layer = Dense(18)(x)\n","\n","\n","    model = models.Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","# Define the input shape (adjust according to your data)\n","input_shape = (window, 1)\n","\n","# Build the model\n","model = build_resnet(input_shape)\n","\n","# Compile the model (customize the optimizer, loss, and metrics based on your task)\n","model.compile(optimizer=tf.optimizers.legacy.Adam(), loss='mean_squared_error')\n","\n","# Print the model summary\n","model.summary()\n"]},{"cell_type":"markdown","id":"8131dded-c1d3-4c95-a279-a3fa4b64d63f","metadata":{"id":"8131dded-c1d3-4c95-a279-a3fa4b64d63f"},"source":["# Full convolutional model"]},{"cell_type":"code","execution_count":7,"id":"b17cbfe7-ed9a-4d44-a15f-f7cee6ca897c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1811,"status":"ok","timestamp":1702316454440,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"b17cbfe7-ed9a-4d44-a15f-f7cee6ca897c","outputId":"73894e3c-bee3-47fe-a68e-84653c613d0b"},"outputs":[],"source":["# import tensorflow as tf\n","# from tensorflow.keras import layers, models\n","\n","# def residual_block(x, filters, kernel_size=3, stride=1):\n","#     y = layers.Conv1D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n","#     y = layers.BatchNormalization()(y)\n","#     y = layers.ReLU()(y)\n","\n","#     y = layers.Conv1D(filters, kernel_size=kernel_size, padding='same')(y)\n","#     y = layers.BatchNormalization()(y)\n","\n","#     # If the number of filters is different or the stride is not 1, add a convolutional layer to the shortcut\n","#     if stride != 1 or x.shape[-1] != filters:\n","#         x = layers.Conv1D(filters, kernel_size=1, strides=stride, padding='same')(x)\n","#         x = layers.BatchNormalization()(x)\n","\n","#     out = layers.add([x, y])\n","#     out = layers.ReLU()(out)\n","#     return out\n","\n","# def build_resnet(input_shape, num_classes=1):\n","#     input_layer = layers.Input(shape=input_shape)\n","\n","#     # Initial convolutional layer\n","#     x = layers.Conv1D(32, kernel_size=3, strides=1, padding='same')(input_layer)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.ReLU()(x)\n","\n","#     # Residual blocks\n","#     x = residual_block(x, filters=64, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","\n","#     x = residual_block(x, filters=64, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","#     x = residual_block(x, filters=128, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","#     x = residual_block(x, filters=128, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","\n","#     x = residual_block(x, filters=64, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","#     x = residual_block(x, filters=64, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","#     x = residual_block(x, filters=32, stride=1)\n","#     x = MaxPooling1D(pool_size=2,padding = 'same')(x)\n","\n","#     x = layers.Conv1D(18, kernel_size=3, strides=1, padding='same')(x)\n","\n","#     # Global average pooling\n","#     output_layer = layers.GlobalAveragePooling1D()(x)\n","\n","\n","#     model = models.Model(inputs=input_layer, outputs=output_layer)\n","#     return model\n","\n","# # Define the input shape (adjust according to your data)\n","# input_shape = (window, 1)\n","\n","# # Build the model\n","# model = build_resnet(input_shape)\n","\n","# # Compile the model (customize the optimizer, loss, and metrics based on your task)\n","# model.compile(optimizer=tf.optimizers.legacy.Adam(), loss='mean_squared_error')\n","\n","# # Print the model summary\n","# model.summary()\n"]},{"cell_type":"markdown","id":"69c29384","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":8,"id":"1f4a5ec9-903c-4bd9-b198-dc8a19ea95d3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615602,"status":"ok","timestamp":1702320837894,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"1f4a5ec9-903c-4bd9-b198-dc8a19ea95d3","outputId":"321bf0f9-4900-4c14-966d-ba132aa362e6"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-16 02:04:36.149578: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1360241072 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/16\n"," 64/807 [=>............................] - ETA: 21:11 - loss: 0.0125"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtfk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtfk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/workspaces/ANNDL/.conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = load_model(pre_path + 'models/model_normalized_v2_all_categories_12_epoch.h5')\n","batch_size = 2**11\n","epochs = 16\n","with tf.device('gpu'):\n","    history = model.fit(\n","        x = X_train,\n","        y = y_train,\n","        batch_size = batch_size,\n","        epochs = epochs,\n","        validation_data=(X_validation, y_validation),\n","        callbacks = [\n","            tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=6, restore_best_weights=True),\n","            tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=2, factor=0.9, min_lr=1e-6)\n","        ]\n","    ).history"]},{"cell_type":"code","execution_count":null,"id":"6aedbfc6-bf6a-4ba1-af32-1140e993ea09","metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1702309717161,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"6aedbfc6-bf6a-4ba1-af32-1140e993ea09"},"outputs":[],"source":["#test_loss = model.evaluate(X_test, y_test,batch_size = batch_size)"]},{"cell_type":"code","execution_count":null,"id":"393209fc-5225-462e-8993-ca0a4ff8a611","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":603,"status":"ok","timestamp":1702320838440,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"393209fc-5225-462e-8993-ca0a4ff8a611","outputId":"3080d338-0865-4cbf-f6bf-60b4852dfb7a"},"outputs":[{"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]},{"data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure()\n","plt.plot(history['loss'])\n","plt.plot(history['val_loss'])\n","plt.title('Model loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"546e1d56-9d6a-46db-a93f-777e98924723","metadata":{"executionInfo":{"elapsed":752,"status":"ok","timestamp":1702322362762,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"546e1d56-9d6a-46db-a93f-777e98924723"},"outputs":[],"source":["model.save(pre_path + 'models/model_normalized_v2_all_categories_28_epoch.h5')"]},{"cell_type":"code","execution_count":null,"id":"6eb403c5-54dc-418c-9ea5-eb01ab07a14d","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1702309755643,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"6eb403c5-54dc-418c-9ea5-eb01ab07a14d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d5e864c6","metadata":{},"outputs":[],"source":["model = load_model(pre_path + 'models/model_normalized_v2_all_categories_28_epoch.h5')\n","batch_size = 2**11\n","epochs = 12\n","with tf.device('gpu'):\n","    history = model.fit(\n","        x = X_train,\n","        y = y_train,\n","        batch_size = batch_size,\n","        epochs = epochs,\n","        validation_data=(X_validation, y_validation),\n","        callbacks = [\n","            tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=6, restore_best_weights=True),\n","            tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=2, factor=0.9, min_lr=1e-6)\n","        ]\n","    ).history\n","\n","model.save(pre_path + 'models/model_normalized_v2_all_categories_40_epoch.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
