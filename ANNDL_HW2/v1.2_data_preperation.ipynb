{"cells":[{"cell_type":"code","execution_count":1,"id":"1vrxe1ZPV6YW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16633,"status":"ok","timestamp":1702305951350,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"1vrxe1ZPV6YW","outputId":"fa69ee2a-21ea-47a2-c98e-b2aa0fcf82f3"},"outputs":[],"source":["# import ssl\n","# ssl._create_default_https_context = ssl._create_unverified_context\n","# from google.colab import drive\n","# drive.mount(\"/content/gdrive\")\n","pre_path = \"\" # 'C:\\Users\\Tugrul\\Desktop\\Dersler\\ANN & DL\\HW2'"]},{"cell_type":"code","execution_count":2,"id":"29129ccd","metadata":{},"outputs":[],"source":["# Installing packages:\n","# pip install pandas\n","# python -m pip install -U matplotlib\n","# python3 -m pip install tensorflow[and-cuda]\n","# pip install -U scikit-learn\n","# pip install seaborn\n","# pip install opencv-python\n","# pip install opencv-python-headless\n","# pip install statsmodels\n","# gdown --no-check-certificate --folder <FOLDER URL>"]},{"cell_type":"code","execution_count":5,"id":"f20b81ac-113e-4064-acea-1c2ae43f8043","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":7027,"status":"ok","timestamp":1702305958369,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"f20b81ac-113e-4064-acea-1c2ae43f8043","outputId":"d8362de0-8ae9-4c56-b790-47ac7f42bbe3"},"outputs":[{"data":{"text/html":["<style>:root { --jp-notebook-max-width: 80% !important; }</style>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["from IPython.display import display, HTML\n","display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","seed = 42\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","import numpy as np\n","np.random.seed(seed)\n","import logging\n","import random\n","random.seed(seed)\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","print(tf.__version__)\n","#from tensorflow.keras.applications.mobilenet import preprocess_input\n","from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","import seaborn as sns\n","from sklearn.utils.class_weight import compute_class_weight\n","import cv2\n","from statsmodels.tsa.stattools import acf\n","#%matplotlib widget"]},{"cell_type":"code","execution_count":6,"id":"a32560b4-5d20-4843-9051-dc40f0bd4ee5","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1702305958370,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"a32560b4-5d20-4843-9051-dc40f0bd4ee5"},"outputs":[],"source":["def rolling_window(array, window_shape, stride=1):\n","    array = np.array(array)\n","    shape = (array.shape[0] - window_shape + 1, window_shape)\n","    strides = (array.strides[0],) + array.strides\n","    rolled = np.lib.stride_tricks.as_strided(array, shape=shape, strides=strides)\n","    return rolled[np.arange(0, shape[0], stride)]"]},{"cell_type":"code","execution_count":7,"id":"c0d4e85e-6f9b-4513-93d9-1abc791351cc","metadata":{"executionInfo":{"elapsed":12117,"status":"ok","timestamp":1702305970481,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"c0d4e85e-6f9b-4513-93d9-1abc791351cc"},"outputs":[],"source":["datas = np.load(pre_path + 'training_dataset/training_data.npy', allow_pickle=True)\n","indexes = np.load(pre_path + 'training_dataset/valid_periods.npy', allow_pickle=True)\n","labels = np.load(pre_path + 'training_dataset/categories.npy', allow_pickle=True)"]},{"cell_type":"code","execution_count":8,"id":"d5628de6-3248-423c-865f-74106d0e61f1","metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1702305972026,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"d5628de6-3248-423c-865f-74106d0e61f1"},"outputs":[],"source":["categories = ['A', 'B', 'C', 'D', 'E', 'F']\n","window_sizes = {'A':200, 'B':200, 'C':200, 'D':200, 'E':200, 'F':200}\n","output_window_sizes = {'A':18, 'B':18, 'C':18, 'D':18, 'E':18, 'F':18}\n","encodings = {'A':np.array([1,0,0,0,0,0]).reshape(1,-1),\n","            'B':np.array([0,1,0,0,0,0]).reshape(1,-1),\n","            'C':np.array([0,0,1,0,0,0]).reshape(1,-1),\n","            'D':np.array([0,0,0,1,0,0]).reshape(1,-1),\n","            'E':np.array([0,0,0,0,1,0]).reshape(1,-1),\n","            'F':np.array([0,0,0,0,0,1]).reshape(1,-1),\n","           }\n","\n","\n","validation_sizes = {'A':0.2, 'B':0.2, 'C':0.2, 'D':0.2, 'E':0.2, 'F':0.2}\n","test_sizes = {'A':0.1, 'B':0.1, 'C':0.1, 'D':0.1, 'E':0.1, 'F':0.1}\n","\n","\n","\n","\n","X_train = {}\n","y_train = {}\n","\n","X_validation = {}\n","y_validation = {}\n","\n","X_test = {}\n","y_test = {}\n","\n","stride = 1"]},{"cell_type":"code","execution_count":9,"id":"0efbb49b-553d-4e3f-8b2f-56b42dd7769b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16441,"status":"ok","timestamp":1702305990324,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"0efbb49b-553d-4e3f-8b2f-56b42dd7769b","outputId":"1870bdb1-8a1e-46d2-b592-da4fa0255d77"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------------------------------------\n","A train size =  (344064, 206) (344064, 18)\n","A validation size =  (93103, 206) (93103, 18)\n","A test size =  (41143, 206) (41143, 18)\n","---------------------------------------------------------------\n","B train size =  (264319, 206) (264319, 18)\n","B validation size =  (87362, 206) (87362, 18)\n","B test size =  (87004, 206) (87004, 18)\n","---------------------------------------------------------------\n","C train size =  (331639, 206) (331639, 18)\n","C validation size =  (96050, 206) (96050, 18)\n","C test size =  (158726, 206) (158726, 18)\n","---------------------------------------------------------------\n","D train size =  (408375, 206) (408375, 18)\n","D validation size =  (165116, 206) (165116, 18)\n","D test size =  (113722, 206) (113722, 18)\n","---------------------------------------------------------------\n","E train size =  (291826, 206) (291826, 18)\n","E validation size =  (121625, 206) (121625, 18)\n","E test size =  (83735, 206) (83735, 18)\n","---------------------------------------------------------------\n","F train size =  (11168, 206) (11168, 18)\n","F validation size =  (2726, 206) (2726, 18)\n","F test size =  (2480, 206) (2480, 18)\n"]}],"source":["for i,category in enumerate(categories):\n","    label_filter = labels == category\n","    batch_data = datas[label_filter]\n","    batch_index = indexes[label_filter]\n","    N = batch_data.shape[0]\n","    window = window_sizes[category]\n","    output_window_size = output_window_sizes[category]\n","\n","    #--------------------------------------------------------\n","    X_test[category] = []\n","    y_test[category] = []\n","\n","    X_validation[category] = []\n","    y_validation[category] = []\n","\n","    X_train[category] = []\n","    y_train[category] = []\n","    #--------------------------------------------------------\n","\n","    encode = encodings[category]\n","    test_end = int(N * test_sizes[category])\n","    validation_end = test_end + int(N * validation_sizes[category])\n","    train_end = N\n","\n","\n","    for n in range(N):\n","        start = batch_index[n,0]\n","        end = batch_index[n,1]\n","\n","        if (end - start) < (window + output_window_size + 18):\n","            start_ = end - (window + output_window_size + 18)\n","        else:\n","            start_ = start\n","\n","        x_n = pd.Series(batch_data[n,start_:end])\n","        y_n = rolling_window(x_n[window:],output_window_size,stride)\n","\n","\n","        x_n = rolling_window(x_n,window,stride)[:y_n.shape[0]]\n","\n","        min = np.concatenate([x_n.min(1).reshape(-1,1),y_n.min(1).reshape(-1,1)],1).min(1).reshape(-1,1)\n","        max = np.concatenate([x_n.max(1).reshape(-1,1),y_n.max(1).reshape(-1,1)],1).max(1).reshape(-1,1)\n","\n","\n","        x_n = (x_n - min)/(max - min)\n","        y_n = (y_n - min)/(max - min)\n","\n","        x_n = np.concatenate([x_n,np.repeat(encode,x_n.shape[0], axis=0)],axis = 1)\n","\n","        #--------------------------------------------------------\n","        if n < test_end:\n","            X_test[category].append(x_n)\n","            y_test[category].append(y_n)\n","        elif test_end <= n < validation_end:\n","            X_validation[category].append(x_n)\n","            y_validation[category].append(y_n)\n","        else:\n","            X_train[category].append(x_n)\n","            y_train[category].append(y_n)\n","        #--------------------------------------------------------\n","\n","    #--------------------------------------------------------\n","    X_test[category] = np.concatenate(X_test[category])\n","    y_test[category] = np.concatenate(y_test[category])\n","\n","    X_validation[category] = np.concatenate(X_validation[category])\n","    y_validation[category] = np.concatenate(y_validation[category])\n","\n","    X_train[category] = np.concatenate(X_train[category])\n","    y_train[category] = np.concatenate(y_train[category])\n","    #--------------------------------------------------------\n","    print('---------------------------------------------------------------')\n","    print('{} train size = '.format(category),X_train[category].shape,y_train[category].shape)\n","    print('{} validation size = '.format(category),X_validation[category].shape,y_validation[category].shape)\n","    print('{} test size = '.format(category),X_test[category].shape,y_test[category].shape)\n","\n"]},{"cell_type":"code","execution_count":10,"id":"dd9d7795-ca3b-471c-8e11-79337faec6fa","metadata":{"executionInfo":{"elapsed":148761,"status":"ok","timestamp":1702306140961,"user":{"displayName":"Kudret Esmer","userId":"04564687935771054092"},"user_tz":-60},"id":"dd9d7795-ca3b-471c-8e11-79337faec6fa"},"outputs":[],"source":["np.save(pre_path + 'windowed_training_data/test_X.npy', X_test)\n","np.save(pre_path + 'windowed_training_data/test_y.npy', y_test)\n","\n","np.save(pre_path + 'windowed_training_data/validation_X.npy', X_validation)\n","np.save(pre_path + 'windowed_training_data/validation_y.npy', y_validation)\n","\n","np.save(pre_path + 'windowed_training_data/train_X.npy', X_train)\n","np.save(pre_path + 'windowed_training_data/train_y.npy', y_train)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
